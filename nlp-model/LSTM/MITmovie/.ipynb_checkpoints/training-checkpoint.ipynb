{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "###  Fetch data and Preprocess  ###\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus.reader import *\n",
    "from nltk import flatten\n",
    "\n",
    "\n",
    "# Read the dataset \n",
    "train = ConllCorpusReader('data/MITMovieCorpus',\n",
    "                          'train.txt',\n",
    "                          ['pos', 'words'])\n",
    "\n",
    "\n",
    "test = ConllCorpusReader('data/MITMovieCorpus', \n",
    "                         'test.txt',\n",
    "                          ['pos', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 7816\n",
      "Number of testing records: 1953\n",
      "[('steve', 'B-Actor'), ('mcqueen', 'I-Actor'), ('provided', 'O'), ('a', 'O'), ('thrilling', 'B-Plot'), ('motorcycle', 'I-Plot'), ('chase', 'I-Plot'), ('in', 'I-Plot'), ('this', 'I-Plot'), ('greatest', 'B-Opinion'), ('of', 'I-Opinion'), ('all', 'I-Opinion'), ('ww', 'B-Plot'), ('2', 'I-Plot'), ('prison', 'I-Plot'), ('escape', 'I-Plot'), ('movies', 'I-Plot')]\n"
     ]
    }
   ],
   "source": [
    "##couldnt find the method to get NE so it is represented as POS\n",
    "sentences = train.tagged_sents() + test.tagged_sents()\n",
    "test_sentences = test.tagged_sents() \n",
    "\n",
    "print(\"Number of training records: \" + str(len(train.tagged_sents())))\n",
    "print(\"Number of testing records: \" + str(len(test.tagged_sents())))\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest sentence has 76 words\n"
     ]
    }
   ],
   "source": [
    "largest_sen = max(len(sen) for sen in sentences)\n",
    "print('biggest sentence has {} words'.format(largest_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.600e+01, 1.140e+02, 1.740e+02, 3.122e+03, 3.341e+03, 1.313e+03,\n",
       "        9.220e+02, 4.570e+02, 1.320e+02, 7.100e+01, 5.100e+01, 2.800e+01,\n",
       "        1.600e+01, 5.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 1.000e+00,\n",
       "        1.000e+00, 1.000e+00]),\n",
       " array([ 3.  ,  6.65, 10.3 , 13.95, 17.6 , 21.25, 24.9 , 28.55, 32.2 ,\n",
       "        35.85, 39.5 , 43.15, 46.8 , 50.45, 54.1 , 57.75, 61.4 , 65.05,\n",
       "        68.7 , 72.35, 76.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.hist([len(sen) for sen in sentences], bins=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As seen in the graph above, majority of the sentences contain less than 40 words even though the there is one sentences that contains  words. We will truncate all sentences larger than 30 words and the sentences that hav less than 30 words will be padded. This is done because, the input that is passed into lstm model has to be of same length. If all sentences are forced to be 334len then most of the words will just be padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['i', 'm', 'thinking', 'of', 'the', 'epic', 'movie', 'based', 'on', 'the', 'book', 'by', 'j', 'r', 'r', 'tolkien', 'featuring', 'hobbits', 'wizards', 'elves', 'and', 'a', 'dark', 'magic', 'xxxPADDINGxxx', 'xxxPADDINGxxx', 'xxxPADDINGxxx', 'xxxPADDINGxxx', 'xxxPADDINGxxx', 'xxxPADDINGxxx']\n"
     ]
    }
   ],
   "source": [
    "max_len = 30\n",
    "\n",
    "X = []\n",
    "padded_sent = []\n",
    "x_index = 0\n",
    "for s in sentences:\n",
    "    for i in range(max_len):\n",
    "        if i >= len(s):\n",
    "            padded_sent.append(\"xxxPADDINGxxx\")\n",
    "        else:\n",
    "            padded_sent.append(s[i][0])\n",
    "    \n",
    "    X.append(padded_sent)\n",
    "    padded_sent = []\n",
    "print (len(X[53]))\n",
    "print(X[53])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the named entities, we will encode them as one hot vectors because they are the values that our model will output to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for s in sentences:\n",
    "    for w in s:\n",
    "        tags.append(w[1])\n",
    "tags = list(set(tags))\n",
    "num_tags = len(tags)\n",
    "\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tags2index = {t:i for i,t in enumerate(tags)}\n",
    "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
    "\n",
    "y = [to_categorical(i, num_classes = num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change our words into numbers actually vectors to be specific (this is also also called embedding). Keras has a functional to do this but it requires us to map each unique word to a unique integer which will be passed into the function. The function takes:\n",
    "\n",
    "__input_dim:__ The total no. of unique words in our corpus. <br>\n",
    "__output_dim:__ Size of the vector that we want. <br>\n",
    "__input_length:__ Size of each spicific sentence (60). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9122, 7079, 8779, 9414, 9417, 2090, 7305, 8088, 2675, 4826, 9947, 2534, 10160, 5203, 8700, 3456, 11510, 4559, 9947, 2452, 572, 3705, 1552, 8955, 6481, 1757, 6763, 6763, 6763, 6763]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for s in X:\n",
    "    for w in s:\n",
    "        words.append(w)\n",
    "unique_words = list(set(words))\n",
    "num_words = len(unique_words)\n",
    "\n",
    "words2index = { w: i for i,w in enumerate(unique_words) }\n",
    "X = [[words2index[w] for w in s] for s in X]\n",
    "# X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=tags2index[\"xxxPADDINGxxx\"])\n",
    "print(X[1])\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X,y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda, Flatten\n",
    "import numpy as np\n",
    "\n",
    "input = Input(shape=(max_len,))\n",
    "embedding = Embedding(input_dim = num_words, output_dim = 70, input_length = max_len)(input)\n",
    "\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=False,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
    "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(x)\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_TRAIN, X_TEST = np.array(X_TRAIN), np.array(X_TEST)\n",
    "\n",
    "\n",
    "# print('x_train shape:', X_TRAIN.shape)\n",
    "# print('x_test shape:', X_TEST.shape)\n",
    "# print('out = ', out.shape)\n",
    "\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "# print(X_TRAIN)\n",
    "\n",
    "# print()\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "\n",
    "# print(np.array(Y_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7912 samples, validate on 880 samples\n",
      "Epoch 1/4\n",
      "7912/7912 [==============================] - 446s 56ms/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 0.0507 - val_accuracy: 0.9827\n",
      "Epoch 2/4\n",
      "7912/7912 [==============================] - 2014s 255ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.0365 - val_accuracy: 0.9881\n",
      "Epoch 3/4\n",
      "7912/7912 [==============================] - 445s 56ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0300 - val_accuracy: 0.9899\n",
      "Epoch 4/4\n",
      "7912/7912 [==============================] - 451s 57ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0280 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1a091c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "print('Training...')\n",
    "model.fit(X_TRAIN, np.array(Y_TRAIN),\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           (True ): Pred\n",
      "this          : O\n",
      "2011          : B-Year\n",
      "romantic      : B-Genre\n",
      "comedy        : I-Genre\n",
      "was           : O\n",
      "written       : O\n",
      "by            : O\n",
      "and           : O\n",
      "stars         : O\n",
      "kristen       : B-Actor\n",
      "wiig          : I-Actor\n",
      "as            : O\n",
      "a             : B-Plot\n",
      "woman         : I-Plot\n",
      "whose         : I-Plot\n",
      "life          : I-Plot\n",
      "begins        : I-Plot\n",
      "to            : I-Plot\n",
      "unravel       : I-Plot\n",
      "as            : I-Plot\n",
      "her           : I-Plot\n",
      "friend        : I-Plot\n",
      "is            : I-Plot\n",
      "preparing     : I-Plot\n",
      "to            : I-Plot\n",
      "get           : I-Plot\n",
      "married       : I-Plot\n",
      "xxxPADDINGxxx : O\n",
      "xxxPADDINGxxx : O\n",
      "xxxPADDINGxxx : O\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "i = 27\n",
    "p = model.predict(np.array([X_TEST[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "print(\"{:14} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w,pred in zip(X_TEST[i],p[0]):\n",
    "    print(\"{:14}: {}\".format(unique_words[w],tags[pred]))\n",
    "    \n",
    "#print(len(X_TRAIN[36]))\n",
    "#print(words[X_TRAIN[4][1]])\n",
    "\n",
    "# model.save('inital.model')\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           (True ): Pred\n",
      "this          : O\n",
      "2011          : B-Year\n",
      "romantic      : B-Genre\n",
      "comedy        : I-Genre\n",
      "was           : O\n",
      "written       : O\n",
      "by            : O\n",
      "and           : O\n",
      "stars         : O\n",
      "kristen       : B-Actor\n",
      "wiig          : I-Actor\n",
      "as            : O\n",
      "a             : B-Plot\n",
      "woman         : I-Plot\n",
      "whose         : I-Plot\n",
      "life          : I-Plot\n",
      "begins        : I-Plot\n",
      "to            : I-Plot\n",
      "unravel       : I-Plot\n",
      "as            : I-Plot\n",
      "her           : I-Plot\n",
      "friend        : I-Plot\n",
      "is            : I-Plot\n",
      "preparing     : I-Plot\n",
      "to            : I-Plot\n",
      "get           : I-Plot\n",
      "married       : I-Plot\n",
      "xxxPADDINGxxx : O\n",
      "xxxPADDINGxxx : O\n",
      "xxxPADDINGxxx : O\n"
     ]
    }
   ],
   "source": [
    "i = 27\n",
    "p = loaded_model.predict(np.array([X_TEST[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "print(\"{:14} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w,pred in zip(X_TEST[i],p[0]):\n",
    "    print(\"{:14}: {}\".format(unique_words[w],tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "########WRITE AS JSON\n",
    "with open(\"dictionary.json\", \"w\") as dict_file:\n",
    "    dict_file.write( '[' );\n",
    "    for i in range(num_words):\n",
    "        dict_file.write(json.dumps({\"word\": unique_words[i], \"index\": words2index[unique_words[i]]}))\n",
    "        \n",
    "        if (i < num_words - 1):\n",
    "            dict_file.write( ', ' );\n",
    "    dict_file.write( ']' );\n",
    "    dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"target.txt\", \"w\") as target_file:\n",
    "    for i in range(len(tags)):\n",
    "        target_file.write( str(tags[i]) )\n",
    "        if(i < len(tags) - 1):\n",
    "            target_file.write( ', ' );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
